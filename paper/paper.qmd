---
title: "Analyzing State-Level Respondent Estimates Using Ratio Estimators: A Case Study with 2022 ACS Data"
author: 
  - Yunkai Gu, Anqi Xu, Yitong Wang
thanks: "Code and data are available at: https://github.com/Anjojoo/State-Level-Respondent-Estimates."
date: today
date-format: long
abstract: "This study analyzes state-level respondent estimates using data from the 2022 American Community Survey (ACS) accessed via IPUMS, and focuses on individuals with doctoral degrees and employs the ratio estimator approach to predict total respondents in each state, using California as a reference point. The results reveal discrepancies between estimates and actual figures, highlighting the limitations of assuming uniform ratios across states. These differences are attributed to variations in demographics, educational policies, and economic conditions. The analysis underscores the utility of statistical methods like ratio estimators for scalable estimates while emphasizing the importance of accounting for regional variations in such analyses."
format: pdf
number-sections: true
toc: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(dplyr)
library(knitr)
library(tibble)
```

# Introduction

Understanding the distribution of educational attainment across states is essential for policymakers, educators, and researchers. This study leverages data from the 2022 American Community Survey (ACS), accessed via IPUMS, to investigate state-level educational patterns, specifically focusing on individuals whose highest degree is a doctorate. While previous studies often rely on direct population counts, this work introduces a statistical perspective by employing the ratio estimator approach, a technique designed to derive population estimates using auxiliary variables.

The study aims to fill a gap in scalable population estimation by testing the applicability of a California-based ratio to other states. California, with its large population and diverse demographics, serves as the benchmark for calculating the proportion of doctoral degree holders to the total respondents. This ratio is then applied to other states to estimate their total number of respondents, allowing for an evaluation of how well such statistical models generalize across varied geographic and demographic contexts.

Results show significant discrepancies between estimated and actual respondent counts in many states, highlighting limitations in assuming uniform ratios. Factors such as state-specific demographics, educational policies, and local economies contribute to these variations. By identifying these differences, the study underscores the importance of incorporating regional nuances into statistical models for more accurate population estimates.

The remainder of this paper is structured as follows:

@sec-data introduces the data obtaining process (@sec-data-obtaining), measurement (@sec-data-measure), as well as an overview of the ratio estimators approach (@sec-data-approach). Then, @sec-result presents the estimates and the actual number of respondents, and further analysis on summary statistics, and @sec-dis discusses the results, and reasons of difference between the estimated result and the actual value. 



# Data {#sec-data}

## Data obtaining {#sec-data-obtaining}

We gather the data from IPUMS USA site, firstly we select “IPUMS USA” on the IPUMS, then clicked “Get Data”, then click “SELECT SAMPLE” and only select “2022 ACS”.  We choose state level data by selecting “HOUSEHOLD”, then choose “GEOGRAPHIC” and add “STATEICP” to cart. For individual level data, we directly search "EDUC" and add it to the cart. After that, we clicked “VIEW CART” , then  click  “CREATE DATA EXTRACT".  We modify the it to csv form. We clicked “SUBMIT EXTRACT" and download it. The data will not be uploaded to github due to its large size, and the prohibition of IPUMs.

The analyses presented in this paper were conducted using R programming language [@citeR]. The `tidyverse` packages [@citetidyverse] were used in the process of data simulation, testing beforehand. After the original raw data was downloaded by using `tidyverse` package [@citetidyverse], data cleaning process was done by using `tidyverse` package [@citetidyverse]. We also use `tidyverse` package [@citetidyverse] to develop the test for structure and format of simulation and analysis data. Tables were constructed with `knitr` package [@citeknitr] and `tibble` package [@citetibble].

@tbl-1 shows the number of respondents that had a doctoral degree as their highest educational attainment in each state.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-1
#| tbl-cap: "Respondents with a doctoral degree as their highest educational attainment in each state"

data <- read.csv(file = here::here("data/01-analysis_data/analysis_data.csv"))

doctoral_data <- data %>% 
  filter(EDUCD == 116) %>% 
  group_by(STATEICP) %>%
  summarize(doctoral_count = n())

doctoral_data %>%
  kable(format = "simple", col.names = c('State', 'Doctoral Counts'))
```

## Measurement {#sec-data-measure}

This paper uses IPUMS to access 2022 American Community Survey (ACS), focusing on the real-world phenomenon of educational attainment — specifically, individuals obtaining a doctoral degree. As society has been paying arising attention to a specific person’s education progress, we find this widespread social phenomenon a meaningful topic to make investigations on.
We used the raw dataset from IPUMS USA, which provides a large database containing data collected from surveys or census activities by U.S. Census and American Community Survey from 1850 to the present. [@ipums-us] The raw data was downloaded from the website and stored in a structured table with columns of STATEICP (indicating the state information of each respondent), EDUC (indicating highest educational attainment of each respondent, i.e. a doctoral degree, which is the topic we have been working on) and other columns presenting various pieces of information gathered from the respondent.
Then, we cleaned the raw dataset, removing incomplete and unnecessary columns and rows to make our analysis clearer. In particular, we selected the EDUC column and STATEICP column to keep valuable information and processed the data to show the number of respondents in each state that had a doctoral degree as their highest educational attainment.
Steps went on to the estimation approach, where we used Laplace ratio estimator to estimate the total number of respondents in each state, given the number of respondents (391,171) in California. This is a statistical method to obtain counts of respondents without acknowledging every piece of information, which is convenient and easy for computing following statistical analysis.
Although the method could be helpful, it may also lead to biases. This is because the Laplace estimating method is based on the assumption that the proportion of doctoral degree holders is similar across states, which could not be held in real-life situations. Therefore, the differences between real-world data (actual survey responses) and statistical estimates as inferred from California's data was calculated to investigate whether the ratio provides a good estimate and to consider the underlying reason explaining the differences.

## Overview of the ratio estimators approach {#sec-data-approach}

The ratio estimator is a method used to improve the accuracy of estimates for a population parameter when there is an auxiliary variable related to the variable of interest. In this case, the objective is to estimate the total number of respondents in each state in the 2022 ACS dataset, given the known number of respondents with doctoral degrees in each state and the California ratio.

With the given total number of respondents in California across all education levels and the number of respondents in California who have a doctoral degree which is available in the data, we can calculate the ratio by the following:

$$
Ratio=\frac{\text{Total number of respondents}}{\text{Number of doctoral respondents}}
$$
Once the ratio is known for California, it is assumed that this ratio is similar across other states. This is the core assumption of the ratio estimator: that the proportion of doctoral degree holders to total respondents is similar across states.

For each state, the estimated total number of respondents is calculated by applying the ratio derived from California:

$$\text{Estimated Total Respondents in State}=\frac{\text{Number of doctoral respondents in state}}{\text{Ratio}}$$


# Results {#sec-result}

## Estimates and the actual number of respondents


@tbl-2 shows the number of estimated total respondents in each state by estimators approach of Laplace.


```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-2
#| tbl-cap: "Number of Estimated Total Respondents in Each State"


# Extract the number of doctoral degree holders in California
california_doctoral <- doctoral_data %>% 
  filter(STATEICP == 71) %>% 
  pull(doctoral_count)

california_total_respondents <- 391171

# Calculate the ratio of doctoral degrees to total respondents in California
california_ratio <- california_doctoral / california_total_respondents

# Apply the ratio to estimate total number of respondents in each state
estimated_data <- doctoral_data %>%
  mutate(estimated_total_respondents = round(doctoral_count / california_ratio, 1))

estimated_data %>% select(-doctoral_count) %>%
  kable(format = "simple", col.names = c('State',  'Estimated Respondents'))
```


@tbl-3 shows the actual respondent and the difference between estimation and the actual number of respondents in each state.


```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-3
#| tbl-cap: "Number of Actual Total Respondents and the Difference in Each State"


#To get the total number of respondents per state
state_totals <- data %>%
  group_by(STATEICP) %>%
  summarize(total_count_respondents = n())


# Join datasets
state_counts <- estimated_data %>%
  inner_join(state_totals, by = "STATEICP")

state_counts <- state_counts %>%
  mutate(difference = total_count_respondents - estimated_total_respondents)

state_counts %>% select(-doctoral_count) %>%
  kable(format = "simple", col.names = c('State', "Estimated Respondents", 
                                         "Actual Respondents", "Difference"))
```

## Summary Statistics

The following three tables present the summary statistics of estimated number of respondents, actual number of respondents and differences between two counts (actual number - estimated number). Specifically, @tbl-4 is for estimated total respondents, @tbl-5 is for actual total respondents, and @tbl-6 is for the difference between two number.


```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-4
#| tbl-cap: "Summary Statistics of Estimated Total Respondents"

# Summary statistics for the estimated column
summary_stats_1 <- state_counts %>%
  summarize(
    estimated_total_respondents_mean = mean(estimated_total_respondents, na.rm = TRUE),
    estimated_total_respondents_sd = sd(estimated_total_respondents, na.rm = TRUE),
    estimated_total_respondents_min = min(estimated_total_respondents, na.rm = TRUE),
    estimated_total_respondents_max = max(estimated_total_respondents, na.rm = TRUE)
  )

# Convert the summary stats to a tibble for proper column naming
summary_stats_tibble_1 <- as_tibble(summary_stats_1)

# Rename columns for clearer labeling in kable
colnames(summary_stats_tibble_1) <- c(
  'Estimated Mean', 'Estimated SD', 'Estimated Min', 'Estimated Max'
)

# Use kable to display the summary statistics table
summary_stats_tibble_1 %>%
  kable(format = "simple")
```



```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-5
#| tbl-cap: "Summary Statistics of Actual Total Respondents"

# Summary statistics for actual column
summary_stats_2 <- state_counts %>%
  summarize(
    total_count_respondents_mean = mean(total_count_respondents, na.rm = TRUE),
    total_count_respondents_sd = sd(total_count_respondents, na.rm = TRUE),
    total_count_respondents_min = min(total_count_respondents, na.rm = TRUE),
    total_count_respondents_max = max(total_count_respondents, na.rm = TRUE)
  )

# Convert the summary stats to a tibble for proper column naming
summary_stats_tibble_2 <- as_tibble(summary_stats_2)

# Rename columns for clearer labeling in kable
colnames(summary_stats_tibble_2) <- c(
  'Actual Mean', 'Actual SD', 'Actual Min', 'Actual Max'
)

# Use kable to display the summary statistics table
summary_stats_tibble_2 %>%
  kable(format = "simple")
```



```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-6
#| tbl-cap: "Summary Statistics of Difference (Actual Minus Estimated Counts)"

# Summary statistics for the difference column
summary_stats_3 <- state_counts %>%
  summarize(
    difference_mean = mean(difference, na.rm = TRUE),
    difference_sd = sd(difference, na.rm = TRUE),
    difference_min = min(difference, na.rm = TRUE),
    difference_max = max(difference, na.rm = TRUE)
  )

# Convert the summary stats to a tibble for proper column naming
summary_stats_tibble_3 <- as_tibble(summary_stats_3)

# Rename columns for clearer labeling in kable
colnames(summary_stats_tibble_3) <- c(
  'Difference Mean', 'Difference SD', 'Difference Min', 'Difference Max'
)

# Use kable to display the summary statistics table
summary_stats_tibble_3 %>%
  kable(format = "simple")
```


@tbl-4 and @tbl-5 shows that on average, the actual total respondents (shown by @tbl-5) are higher than the estimated total respondents (shown by @tbl-4). 

Specifically, the estimated mean (53359.66) is much smaller than the actual mean (66144.67). This noticeable gap between two numbers suggest that the estimator used may lead to underestimation of the number of total respondents in most states.

The difference mean in @tbl-6 is 12785.01, which also implies that there's underestimation on average. The value means that on average, the actual number of respondents is greater than the estimated value by around 12785 people.

@tbl-6 also reveals large range of differences between actual and estimated counts of respondents. The minimum difference is -51263.02, suggesting that in one of the most extreme cases, the actual number is much lower than the estimated one. This may caused by specific characteristics for some states, which led to the violation of the assumption of the Laplace ratio estimator (which assumes that the proportion of doctoral degree holders is similar across states).

On the other hand, the maximum difference is 94370, indicating that in another extreme case, the actual number is much higher than the estimated one. The huge gap between maximum and minimum value of difference reveals the fact that the estimator might not generalize well to all the states across the country, and that the estimating process may not be appropriate in some cases.


# Discussion {#sec-dis}
## Reason of Difference

The primary assumption for this estimation model to work is that the ratio of doctoral degree holders to total respondents in California is similar to that in other states. If this is not the case, the ratio estimator could produce biased estimates, overestimating or underestimating the number of respondents in other states, depending on the state’s specific characteristics.

Though the assumption makes our analysis and estimating process become convenient, this is a non-realistic assumption for real-life situations. There exist various demographic factors which would lead to the failure of the assumption. 

For instance, rural states may have lower educational attainment due to the lack of universities, schools and research institutions, compared to the states with more urban regions. 

Some states may have cultural factors or socioeconomic characteristics that make the educational attainment situation become different from that of California. 

Other factors like local policies may also cause the actual ratios to differ, leading to discrepancies between the estimates and actual values.


# References


